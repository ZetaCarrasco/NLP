{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["---\n","This paper further discusses the RAG training, including RAGwith/without datastore update. Then, we introduce the application of RAG in representative natural language processing tasks and industrial scenarios. Finally, this paper discusses the future directions and challenges of RAG for promoting its development\n","lengthText: 314\n","---\n","[84, 104, 105, 115, 32, 112, 97, 112, 101, 114, 32, 102, 117, 114, 116, 104, 101, 114, 32, 100, 105, 115, 99, 117, 115, 115, 101, 115, 32, 116, 104, 101, 32, 82, 65, 71, 32, 116, 114, 97, 105, 110, 105, 110, 103, 44, 32, 105, 110, 99, 108, 117, 100, 105, 110, 103, 32, 82, 65, 71, 119, 105, 116, 104, 47, 119, 105, 116, 104, 111, 117, 116, 32, 100, 97, 116, 97, 115, 116, 111, 114, 101, 32, 117, 112, 100, 97, 116, 101, 46, 32, 84, 104, 101, 110, 44, 32, 119, 101, 32, 105, 110, 116, 114, 111, 100, 117, 99, 101, 32, 116, 104, 101, 32, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 32, 111, 102, 32, 82, 65, 71, 32, 105, 110, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 97, 116, 105, 118, 101, 32, 110, 97, 116, 117, 114, 97, 108, 32, 108, 97, 110, 103, 117, 97, 103, 101, 32, 112, 114, 111, 99, 101, 115, 115, 105, 110, 103, 32, 116, 97, 115, 107, 115, 32, 97, 110, 100, 32, 105, 110, 100, 117, 115, 116, 114, 105, 97, 108, 32, 115, 99, 101, 110, 97, 114, 105, 111, 115, 46, 32, 70, 105, 110, 97, 108, 108, 121, 44, 32, 116, 104, 105, 115, 32, 112, 97, 112, 101, 114, 32, 100, 105, 115, 99, 117, 115, 115, 101, 115, 32, 116, 104, 101, 32, 102, 117, 116, 117, 114, 101, 32, 100, 105, 114, 101, 99, 116, 105, 111, 110, 115, 32, 97, 110, 100, 32, 99, 104, 97, 108, 108, 101, 110, 103, 101, 115, 32, 111, 102, 32, 82, 65, 71, 32, 102, 111, 114, 32, 112, 114, 111, 109, 111, 116, 105, 110, 103, 32, 105, 116, 115, 32, 100, 101, 118, 101, 108, 111, 112, 109, 101, 110, 116]\n","lengthTokens: 314\n"]}],"source":["text=\"This paper further discusses the RAG training, including RAGwith/without datastore update. Then, we introduce the application of RAG in representative natural language processing tasks and industrial scenarios. Finally, this paper discusses the future directions and challenges of RAG for promoting its development\"\n","tokens = text.encode(\"utf-8\")\n","tokens = list(map(int, tokens))\n","print ('---')\n","print(text)\n","print(\"lengthText:\", len(text))\n","print('---')\n","print(tokens)\n","print(\"lengthTokens:\", len(tokens))"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{(84, 104): 1}\n"]}],"source":["def get_stats(ids):\n","    counts ={}\n","    for pair in zip(ids, ids[1:]):\n","        counts[pair]= counts.get(pair,0)+1\n","        return counts\n","stats=get_stats(tokens)\n","print(stats)\n","#print(sorted((V,K)for K,V in stats.items()), reverse=True())        "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["(84, 104)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["top_pair= max(stats, key=stats.get)\n","top_pair"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def merge(ids, pair, idx):\n","    newids = []\n","    i = 0\n","    while i< len(ids):\n","        if i <len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n","            newids.append(idx)\n","            i+=2\n","        else:\n","            newids.append(ids[i])\n","            i+=1\n","    return newids"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[5, 6, 99, 9, 1]\n"]}],"source":["print(merge([5, 6, 6, 7, 9, 1], (6, 7), 99))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[256, 105, 115, 32, 112, 97, 112, 101, 114, 32, 102, 117, 114, 116, 104, 101, 114, 32, 100, 105, 115, 99, 117, 115, 115, 101, 115, 32, 116, 104, 101, 32, 82, 65, 71, 32, 116, 114, 97, 105, 110, 105, 110, 103, 44, 32, 105, 110, 99, 108, 117, 100, 105, 110, 103, 32, 82, 65, 71, 119, 105, 116, 104, 47, 119, 105, 116, 104, 111, 117, 116, 32, 100, 97, 116, 97, 115, 116, 111, 114, 101, 32, 117, 112, 100, 97, 116, 101, 46, 32, 256, 101, 110, 44, 32, 119, 101, 32, 105, 110, 116, 114, 111, 100, 117, 99, 101, 32, 116, 104, 101, 32, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 32, 111, 102, 32, 82, 65, 71, 32, 105, 110, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 97, 116, 105, 118, 101, 32, 110, 97, 116, 117, 114, 97, 108, 32, 108, 97, 110, 103, 117, 97, 103, 101, 32, 112, 114, 111, 99, 101, 115, 115, 105, 110, 103, 32, 116, 97, 115, 107, 115, 32, 97, 110, 100, 32, 105, 110, 100, 117, 115, 116, 114, 105, 97, 108, 32, 115, 99, 101, 110, 97, 114, 105, 111, 115, 46, 32, 70, 105, 110, 97, 108, 108, 121, 44, 32, 116, 104, 105, 115, 32, 112, 97, 112, 101, 114, 32, 100, 105, 115, 99, 117, 115, 115, 101, 115, 32, 116, 104, 101, 32, 102, 117, 116, 117, 114, 101, 32, 100, 105, 114, 101, 99, 116, 105, 111, 110, 115, 32, 97, 110, 100, 32, 99, 104, 97, 108, 108, 101, 110, 103, 101, 115, 32, 111, 102, 32, 82, 65, 71, 32, 102, 111, 114, 32, 112, 114, 111, 109, 111, 116, 105, 110, 103, 32, 105, 116, 115, 32, 100, 101, 118, 101, 108, 111, 112, 109, 101, 110, 116]\n","length: 312\n"]}],"source":["tokens2 = merge(tokens, top_pair, 256)\n","print(tokens2)\n","print('length:', len(tokens2))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["vocab_size = 276\n","num_merges = vocab_size - 256\n","ids = list(tokens)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["merging (84, 104) into a new token 275\n"]}],"source":["merges = {}\n","for i in range(num_merges):\n","    stats = get_stats(ids)\n","    pair = max(stats, key=stats.get)\n","    idx = 256 + i\n","print(f\"merging {pair} into a new token {idx}\")\n","ids = merge(ids, pair, idx)\n","merges [pair] = idx    "]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tokens length: 314\n","ids length: 312\n","compression ratio: 1.006410X\n"]}],"source":["print(\"tokens length:\", len(tokens))\n","print(\"ids length:\", len(ids))\n","print(f\"compression ratio: {len(tokens) / len(ids):2f}X\")"]},{"cell_type":"markdown","metadata":{},"source":["ecoding"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["vocab = {idx: bytes ([idx] )for idx in range(256) }\n","for (p0, p1), idx in merges.items():\n","    vocab[idx] = vocab [p0] + vocab [p1]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["!\n"]}],"source":["def decode (ids): \n","    tokens = b\"\".join(vocab[idx] for idx in ids)\n","    text = tokens.decode(\"utf-8\", errors=\"replace\")\n","    return text\n","print(decode([33]))"]},{"cell_type":"markdown","metadata":{},"source":["ncoding"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[72, 97, 118, 101, 32, 97, 32, 110, 105, 99, 101, 32, 100, 97, 121, 33]\n"]}],"source":["def encode(text):\n","    tokens =  list(text.encode(\"utf-8\"))\n","    while True:\n","        stats =  get_stats(tokens)\n","        pair = min(stats, key= lambda p: merges.get(p, float (\"inf\")))\n","        if pair not in merges:\n","            break\n","        idx = merges[pair]\n","        tokens =  merge(tokens, pair, idx)\n","    return tokens\n","print(encode(\"Have a nice day!\")) "]},{"cell_type":"markdown","metadata":{},"source":["ara verificar se o decode e encode estÃ¡ correto"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","True\n"]}],"source":["text1 = decode(encode(text))\n","print(text1 == text)\n","#verificando outro texto que o tokenizer nÃ£o conhece\n","valtext = \"This acceleration was largely driven by three synergistic trends. First, large amounts of spoken and written material became widely available through the auspices of the Linguistic Data Consortium (LDC).\"\n","valtext2 = decode(encode(valtext))\n","print(valtext2 == valtext)"]},{"cell_type":"markdown","metadata":{},"source":["ivide o texto em uma lista de texto e cada um Ã© processado diferente"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['How', ' is', ' going', '.', ' I', \"'m\", ' great']\n"]}],"source":["import regex as re\n","gpt2pat = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n","print(re.findall(gpt2pat, \"How is going. I'm great\"))  "]},{"cell_type":"markdown","metadata":{},"source":["rabalha com os espaÃ§os "]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[220, 220, 220, 220, 220, 220, 23748, 995, 13896]\n"]}],"source":["import tiktoken\n","enc = tiktoken.get_encoding(\"gpt2\")\n","print(enc.encode(\"       hello world!!!!\"))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[996, 24748, 1917, 17523]\n"]}],"source":["enc = tiktoken.get_encoding(\"cl100k_base\")\n","print(enc.encode(\"       hello world!!!!\"))"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import os, json"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["50257\n"]}],"source":["with open('encoder.json', 'r') as f:\n","    encoder = json.load(f)\n","    \n","with open('vocab.bpe', 'r', encoding=\"utf-8\") as f:\n","    bpe_data = f.read()\n","bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split('\\n')[1:-1]]\n","print(len(encoder))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
